import lightgbm
import numpy as np
from ember import PEFeatureExtractor
from secml.array import CArray
from secml.ml.classifiers import CClassifier


class CClassifierEmber(CClassifier):
	"""
	The wrapper for the EMBER GBDT, by Anderson et al. https://arxiv.org/abs/1804.04637
	"""

	def __init__(self, tree_path: str = None, X: CArray = None, y: CArray = None):
		"""
		Create the EMBER tree.

		Parameters
		----------
        tree_path : str, optional
            Path to the tree parameters
        X : CArray, optional
            Training features
        y : CArray, optional
            Training labels
		"""
		super(CClassifierEmber, self).__init__()
		if tree_path:
			print("Loading the tree...")
			self._lightgbm_model = self._load_tree(tree_path)
		elif X is not None and y is not None:
			print("Training the model...")
			self._n_features = X.shape[1]
			if self._n_features == 2351:
				self._feature_version = 1
			elif self._n_features == 2381:
				self._feature_version = 2
			else:
				error_message = (
					"The number of features does not match the supported versions. "
					"X must contain ember features in version 1 (2351) or version 2 (2381)."
				)
				raise ValueError(error_message)
			self._classes = 2
			self._lightgbm_model = self._fit(X, y)
			
	def extract_features(self, x: CArray) -> CArray:
		"""
		Extract EMBER features

		Parameters
		----------
		x : CArray
			program sample
		Returns
		-------
		CArray
			EMBER features
		"""
		extractor = PEFeatureExtractor(self._feature_version, print_feature_warning=False)
		x = x.atleast_2d()
		size = x.shape[0]
		features = []
		for i in range(size):
			x_i = x[i, :]
			length = x_i.find(x_i == 256)
			if length:
				x_i = x_i[0, :length[0]]
			x_bytes = bytes(x_i.astype(np.uint8).tolist()[0])
			features.append(np.array(extractor.feature_vector(x_bytes), dtype=np.float32))
		features = CArray(features)
		return features

	def _backward(self, w):
		pass

	def _fit(self, X: CArray, y: CArray, init_model=None):
		lgbm_dataset = lightgbm.Dataset(X, y)
		lgbm_model = lightgbm.train(params={"application": "binary"}, train_set=lgbm_dataset, init_model=init_model)
		self._lightgbm_model = lgbm_model
		print("Model trained successfully.")
		return lgbm_model

	def _load_tree(self, tree_path):
		booster = lightgbm.Booster(model_file=tree_path)
		self._classes = 2
		self._n_features = booster.num_feature()
		if self._n_features == 2351:
			self._feature_version = 1
		elif self._n_features == 2381:
			self._feature_version = 2
		else:
			error_message = (
				"The number of features does not match the supported versions. "
				"The model must use ember features in version 1 (2351) or version 2 (2381)."
			)
			raise ValueError(error_message)
		print("Tree loaded successfully.")
		return booster

	def _forward(self, x):
		x = x.atleast_2d()
		scores = self._lightgbm_model.predict(x.tondarray())
		confidence = [[1 - c, c] for c in scores]
		confidence = CArray(confidence)
		return confidence

	def predict(self, x, return_decision_function=False):

		scores = self.decision_function(x, y=None)

		# Checking if the score is higher than ember model threshold
		labels = (scores > 0.82).astype(int)

		label = labels.argmax(axis=1).ravel()

		return (label, scores) if return_decision_function is True else labels

	def save_model(self, path: str):
		self._lightgbm_model.save_model(path)